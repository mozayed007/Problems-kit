# Unified 16‑Day Implementation & Review Plan

**Daily Commitment:** 4 Hours  
**Total Duration:** 16 Days

Each challenge entry lists:

- **ID / Title**

- **Difficulty**

- **Category**

- **Platform** (DeepML or LeetGPU)

- Checkboxes for **Python**, **Triton**, and **CUDA** implementations

---

## **Group 1: Fundamental Linear Algebra & Basic ML Operations**

**Prerequisites (Review):**

- Basic vector/matrix operations (addition, multiplication, dot product)

- Matrix transposition, reshaping

- Introductory statistics (mean, covariance)

- Fundamental ML concepts (linear regression basics)

**Unified Checklist:**

|Status|ID / Title|Difficulty|Category|Platform|Python|Triton|CUDA|
|---|---|---|---|---|---|---|---|
|[ ]|1. Matrix-Vector Dot Product|easy|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|2. Transpose of a Matrix|easy|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|3. Reshape Matrix|easy|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|4. Calculate Mean by Row or Column|easy|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|5. Scalar Multiplication of a Matrix|easy|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|10. Calculate Covariance Matrix|easy|Statistics|DeepML|[ ]|[ ]|[ ]|
|[ ]|14. Linear Regression Using Normal Equation|easy|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|15. Linear Regression Using Gradient Descent|easy|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|16. Feature Scaling Implementation|easy|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|22. Sigmoid Activation Function Understanding|easy|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|23. Softmax Activation Function Implementation|easy|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|24. Single Neuron|easy|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|27. Transformation Matrix from Basis B to C|easy|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|29. Random Shuffle of Dataset|easy|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|30. Batch Iterator for Dataset|easy|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|Vector Addition|easy|Basic Operation|LeetGPU|[ ]|[ ]|[ ]|
|[ ]|Matrix Multiplication|easy|Linear Algebra|LeetGPU|[ ]|[ ]|[ ]|
|[ ]|Matrix Transpose|easy|Linear Algebra|LeetGPU|[ ]|[ ]|[ ]|
|[ ]|Reverse Array|easy|Array Operation|LeetGPU|[ ]|[ ]|[ ]|
|[ ]|Dot Product|medium|Linear Algebra|LeetGPU|[ ]|[ ]|[ ]|

**Schedule (Days 1–2):**

- **Day 1:**

  - _Hour 1:_ Quick review of basic linear algebra (vectors, matrices).

  - _Hours 2–4:_ Implement DeepML problems 1–5.

- **Day 2:**

  - _Hour 1:_ Brief review of mean, covariance, and linear regression basics.

  - _Hours 2–4:_ Implement DeepML problems 10, 14, 15, 16, 22, 23, 24, 27, 29, 30; then implement LeetGPU Vector Addition, Matrix Multiplication, Matrix Transpose, Reverse Array, and Dot Product.

---

## **Group 2: Data Transformations, Metrics & Activation Functions**

**Prerequisites (Review):**

- Data manipulation (one‑hot encoding, converting vectors to diagonal matrices)

- Basic performance metrics (accuracy, precision, recall, F‑score)

- Activation function basics (sigmoid, softmax, ReLU variants)

**Unified Checklist:**

|Status|ID / Title|Difficulty|Category|Platform|Python|Triton|CUDA|
|---|---|---|---|---|---|---|---|
|[ ]|34. One‑Hot Encoding of Nominal Values|easy|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|35. Convert Vector to Diagonal Matrix|easy|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|36. Calculate Accuracy Score|easy|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|39. Implementation of Log Softmax Function|easy|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|42. Implement ReLU Activation Function|easy|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|43. Implement Ridge Regression Loss Function|easy|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|44. Leaky ReLU Activation Function|easy|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|45. Linear Kernel Function|easy|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|46. Implement Precision Metric|easy|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|52. Implement Recall Metric in Binary Classification|easy|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|56. KL Divergence Between Two Normal Distributions|easy|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|61. Implement F‑Score Calculation for Binary Classification|easy|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|64. Implement Gini Impurity Calculation for a Set of Classes|easy|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|65. Implement Compressed Row Sparse Matrix (CSR) Format Conversion|easy|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|66. Implement Orthogonal Projection of a Vector onto a Line|easy|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|Softmax|easy|Activation|LeetGPU|[ ]|[ ]|[ ]|
|[ ]|ReLU Activation|easy|Activation|LeetGPU|[ ]|[ ]|[ ]|

**Schedule (Days 3–4):**

- **Day 3:**

  - _Hour 1:_ Review one‑hot encoding and basic data transformation techniques.

  - _Hours 2–4:_ Implement DeepML problems 34, 35, 36, and 39, 42, 43, 44.

- **Day 4:**

  - _Hour 1:_ Briefly revisit performance metrics (accuracy, precision, etc.).

  - _Hours 2–4:_ Implement DeepML problems 45, 46, 52, 56, 61, 64, 65, 66; then implement LeetGPU Softmax and ReLU Activation.

---

## **Group 3: Statistical Calculations & Evaluation Metrics**

**Prerequisites (Review):**

- Descriptive statistics and probability distributions

- Evaluation metrics for classification and regression

- Sparse data representations

**Unified Checklist:**

|Status|ID / Title|Difficulty|Category|Platform|Python|Triton|CUDA|
|---|---|---|---|---|---|---|---|
|[ ]|67. Implement Compressed Column Sparse Matrix (CSC) Format|easy|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|69. Calculate R‑squared for Regression Analysis|easy|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|70. Calculate Image Brightness|easy|Computer Vision|DeepML|[ ]|[ ]|[ ]|
|[ ]|71. Calculate Root Mean Square Error (RMSE)|easy|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|72. Calculate Jaccard Index for Binary Classification|easy|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|73. Calculate Dice Score for Classification|easy|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|75. Generate a Confusion Matrix for Binary Classification|easy|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|76. Calculate Cosine Similarity Between Vectors|easy|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|78. Descriptive Statistics Calculator|easy|Statistics|DeepML|[ ]|[ ]|[ ]|
|[ ]|81. Poisson Distribution Probability Calculator|easy|Probability|DeepML|[ ]|[ ]|[ ]|
|[ ]|82. Grayscale Image Contrast Calculator|easy|Computer Vision|DeepML|[ ]|[ ]|[ ]|
|[ ]|83. Dot Product Calculator|easy|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|84. Phi Transformation for Polynomial Features|easy|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|86. Detect Overfitting or Underfitting|easy|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|91. Calculate F1 Score from Predicted and True Labels|easy|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|Histogramming|medium|Statistics|LeetGPU|[ ]|[ ]|[ ]|
|[ ]|Sorting|medium|Algorithm|LeetGPU|[ ]|[ ]|[ ]|
|[ ]|Prefix Sum|medium|Reduction|LeetGPU|[ ]|[ ]|[ ]|
|[ ]|Sparse Matrix‑Vector Multiplication|medium|Linear Algebra|LeetGPU|[ ]|[ ]|[ ]|

**Schedule (Days 5–6):**

- **Day 5:**

  - _Hour 1:_ Quick review of key statistical concepts and probability distributions.

  - _Hours 2–4:_ Implement DeepML problems 67, 69, 70, 71, 72, 73, and 75.

- **Day 6:**

  - _Hour 1:_ Review similarity measures and vector operations.

  - _Hours 2–4:_ Complete DeepML problems 76, 78, 81, 82, 83, 84, 86, and 91; then implement LeetGPU Histogramming, Sorting, Prefix Sum, and Sparse Matrix‑Vector Multiplication.

---

## **Group 4: Advanced Activations, Normalization & Architectural Blocks**

**Prerequisites (Review):**

- Advanced activation functions (ELU, PReLU, Softplus, Softsign, Swish, SELU)

- Normalization techniques (min‑max, batch normalization)

- Neural network building blocks (residual blocks, global average pooling)

**Unified Checklist:**

|Status|ID / Title|Difficulty|Category|Platform|Python|Triton|CUDA|
|---|---|---|---|---|---|---|---|
|[ ]|93. Calculate Mean Absolute Error (MAE)|easy|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|95. Calculate the Phi Coefficient|easy|Statistics|DeepML|[ ]|[ ]|[ ]|
|[ ]|96. Implement the Hard Sigmoid Activation Function|easy|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|97. Implement the ELU Activation Function|easy|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|98. Implement the PReLU Activation Function|easy|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|99. Implement the Softplus Activation Function|easy|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|100. Implement the Softsign Activation Function|easy|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|102. Implement the Swish Activation Function|easy|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|103. Implement the SELU Activation Function|easy|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|104. Binary Classification with Logistic Regression|easy|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|108. Measure Disorder in Apple Colors|easy|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|112. Min‑Max Normalization of Feature Values|easy|Data Preprocessing|DeepML|[ ]|[ ]|[ ]|
|[ ]|113. Implement a Simple Residual Block with Shortcut Connection|easy|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|114. Implement Global Average Pooling|easy|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|115. Implement Batch Normalization for BCHW Input|easy|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|1D Convolution|easy|Convolution|LeetGPU|[ ]|[ ]|[ ]|
|[ ]|Color Inversion|easy|Image Processing|LeetGPU|[ ]|[ ]|[ ]|
|[ ]|2D Convolution|medium|Convolution|LeetGPU|[ ]|[ ]|[ ]|

**Schedule (Days 7–8):**

- **Day 7:**

  - _Hour 1:_ Review advanced activations and normalization techniques.

  - _Hours 2–4:_ Implement DeepML problems 93, 95, 96, 97, 98, 99, and 100.

- **Day 8:**

  - _Hour 1:_ Brief review of residual block architectures and pooling.

  - _Hours 2–4:_ Implement DeepML problems 102, 103, 104, 108, 112, 113, 114, 115; then implement LeetGPU challenges 1D Convolution, Color Inversion, and 2D Convolution.

---

## **Group 5: Advanced Linear Algebra & Complex ML/DL Methods**

**Prerequisites (Review):**

- Advanced linear algebra (SVD, eigenvalues, determinants, cross product)

- Numerical optimization methods (gradient descent, conjugate gradient)

- Advanced ML topics (decision trees, SVM, AdaBoost)

- Custom NN components (dense layers, RNNs, positional encoding)

**Unified Checklist:**

|Status|ID / Title|Difficulty|Category|Platform|Python|Triton|CUDA|
|---|---|---|---|---|---|---|---|
|[ ]|116. Derivative of a Polynomial|easy|Calculus|DeepML|[ ]|[ ]|[ ]|
|[ ]|118. Compute the Cross Product of Two 3D Vectors|easy|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|12. Singular Value Decomposition (SVD)|hard|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|13. Determinant of a 4x4 Matrix using Laplace's Expansion (hard)|hard|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|20. Decision Tree Learning|hard|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|21. Pegasos Kernel SVM Implementation|hard|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|28. SVD of a 2x2 Matrix using eigen values & vectors|hard|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|38. Implement AdaBoost Fit Method|hard|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|40. Implementing a Custom Dense Layer in Python|hard|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|62. Implement a Simple RNN with Backpropagation Through Time (BPTT)|hard|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|63. Implement the Conjugate Gradient Method for Solving Linear Systems|hard|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|85. Positional Encoding Calculator|hard|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|88. GPT‑2 Text Generation|hard|NLP|DeepML|[ ]|[ ]|[ ]|
|[ ]|94. Implement Multi‑Head Attention|hard|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|101. Implement the GRPO Objective Function|hard|Reinforcement Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|GEMM (FP16)|medium|Matrix Multiplication|LeetGPU|[ ]|[ ]|[ ]|

**Schedule (Days 9–10):**

- **Day 9:**

  - _Hour 1:_ Quick review of advanced linear algebra topics (SVD, determinants).

  - _Hours 2–4:_ Implement DeepML problems 116, 118, 12, and 13.

- **Day 10:**

  - _Hour 1:_ Refresh advanced ML methods and optimization techniques.

  - _Hours 2–4:_ Implement DeepML problems 20, 21, 28, 38, 40, 62, 63, 85, 88, 94, 101; then implement LeetGPU GEMM (FP16).

---

## **Group 6: Intermediate Linear Algebra & ML Foundations**

**Prerequisites (Review):**

- Intermediate linear algebra (matrix inversion, solving equations)

- Iterative methods (Jacobi, Gauss‑Seidel)

- Core ML operations (k‑means, cross‑validation, PCA)

- Basic neural network fundamentals

**Unified Checklist:**

|Status|ID / Title|Difficulty|Category|Platform|Python|Triton|CUDA|
|---|---|---|---|---|---|---|---|
|[ ]|105. Train Softmax Regression with Gradient Descent|hard|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|106. Train Logistic Regression with Gradient Descent|hard|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|6. Calculate Eigenvalues of a Matrix|medium|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|7. Matrix Transformation|medium|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|8. Calculate 2x2 Matrix Inverse|medium|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|9. Matrix times Matrix|medium|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|11. Solve Linear Equations using Jacobi Method|medium|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|17. K‑Means Clustering|medium|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|18. Implement K‑Fold Cross‑Validation|medium|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|19. Principal Component Analysis (PCA) Implementation|medium|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|25. Single Neuron with Backpropagation|medium|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|26. Implementing Basic Autograd Operations|medium|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|31. Divide Dataset Based on Feature Threshold|medium|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|32. Generate Polynomial Features|medium|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|33. Generate Random Subsets of a Dataset|medium|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|K‑Means Clustering|hard|Clustering|LeetGPU|[ ]|[ ]|[ ]|

**Schedule (Days 11–12):**

- **Day 11:**

  - _Hour 1:_ Review intermediate linear algebra and iterative methods.

  - _Hours 2–4:_ Implement DeepML problems 105, 106, 6, 7, 8, 9, 11, 17, and 18.

- **Day 12:**

  - _Hour 1:_ Quick refresher on PCA and autograd fundamentals.

  - _Hours 2–4:_ Complete DeepML problems 19, 25, 26, 31, 32, and 33; then implement LeetGPU K‑Means Clustering.

---

## **Group 7: Intermediate Deep Learning & Advanced Algebra Techniques**

**Prerequisites (Review):**

- Intermediate deep learning (RNNs, LSTM, self‑attention)

- Advanced matrix techniques (RREF, gradient descent variants)

- Basic NLP methods

**Unified Checklist:**

|Status|ID / Title|Difficulty|Category|Platform|Python|Triton|CUDA|
|---|---|---|---|---|---|---|---|
|[ ]|37. Calculate Correlation Matrix|medium|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|41. Simple Convolutional 2D Layer|medium|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|47. Implement Gradient Descent Variants with MSE Loss|medium|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|48. Implement Reduced Row Echelon Form (RREF) Function|medium|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|49. Implement Adam Optimization Algorithm|medium|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|50. Implement Lasso Regression using Gradient Descent|medium|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|51. Optimal String Alignment Distance|medium|NLP|DeepML|[ ]|[ ]|[ ]|
|[ ]|53. Implement Self‑Attention Mechanism|medium|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|54. Implementing a Simple RNN|medium|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|55. 2D Translation Matrix Implementation|medium|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|57. Gauss‑Seidel Method for Solving Linear Systems|medium|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|58. Gaussian Elimination for Solving Linear Systems|medium|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|59. Implement Long Short‑Term Memory (LSTM) Network|medium|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|60. Implement TF‑IDF (Term Frequency‑Inverse Document Frequency)|medium|NLP|DeepML|[ ]|[ ]|[ ]|
|[ ]|68. Find the Image of a Matrix Using Row Echelon Form|medium|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|Multi‑Head Self‑Attention|hard|Attention|LeetGPU|[ ]|[ ]|[ ]|

**Schedule (Days 13–14):**

- **Day 13:**

  - _Hour 1:_ Review fundamentals of RNNs, LSTM, and self‑attention.

  - _Hours 2–4:_ Implement DeepML problems 37, 41, 47, 48, 49, 50, and 51.

- **Day 14:**

  - _Hour 1:_ Refresh optimization techniques and basic NLP methods.

  - _Hours 2–4:_ Implement DeepML problems 53, 54, 55, 57, 58, 59, 60, 68; then implement LeetGPU Multi‑Head Self‑Attention.

---

## **Group 8: Mixed Applications – NLP, Metrics, & Specialized Operations**

**Prerequisites (Review):**

- Fundamental NLP concepts (BM25, METEOR, PMI)

- Specialized metrics and composite vector techniques

- Advanced linear algebra (composite hypervectors, orthonormal bases)

**Unified Checklist:**

|Status|ID / Title|Difficulty|Category|Platform|Python|Triton|CUDA|
|---|---|---|---|---|---|---|---|
|[ ]|74. Create Composite Hypervector for a Dataset Row|medium|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|77. Calculate Performance Metrics for a Classification Model|medium|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|79. Binomial Distribution Probability|medium|Probability|DeepML|[ ]|[ ]|[ ]|
|[ ]|80. Normal Distribution PDF Calculator|medium|Probability|DeepML|[ ]|[ ]|[ ]|
|[ ]|87. Adam Optimizer|medium|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|89. The Pattern Weaver's Code|medium|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|90. BM25 Ranking|medium|NLP|DeepML|[ ]|[ ]|[ ]|
|[ ]|92. Linear Regression - Power Grid Optimization|medium|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|107. Implement Masked Self‑Attention|medium|Deep Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|109. Implement Layer Normalization for Sequence Data|medium|Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|110. Evaluate Translation Quality with METEOR Score|medium|NLP|DeepML|[ ]|[ ]|[ ]|
|[ ]|111. Compute Pointwise Mutual Information|medium|NLP|DeepML|[ ]|[ ]|[ ]|
|[ ]|117. Compute Orthonormal Basis for 2D Vectors|medium|Linear Algebra|DeepML|[ ]|[ ]|[ ]|
|[ ]|119. Solve System of Linear Equations Using Cramer’s Rule|medium|Linear Algebra for Machine Learning|DeepML|[ ]|[ ]|[ ]|
|[ ]|3D Convolution|hard|Convolution|LeetGPU|[ ]|[ ]|[ ]|
|[ ]|Swarm Intelligence & Flocking Simulation|hard|Simulation|LeetGPU|[ ]|[ ]|[ ]|

**Schedule (Days 15–16):**

- **Day 15:**

  - _Hour 1:_ Quick review of NLP ranking, specialized metrics, and composite vector techniques.

  - _Hours 2–4:_ Implement DeepML problems 74, 77, 79, 80, 87, 89, 90, 92, 107, and 109.

- **Day 16:**

  - _Hour 1:_ Brief review of translation metrics and pointwise mutual information.

  - _Hours 2–4:_ Complete DeepML problems 110, 111, 117, and 119; then implement LeetGPU challenges 3D Convolution and Swarm Intelligence & Flocking Simulation.

---

## Additional Recommendations

- **Daily Progress:** Update the unified checklist as you complete each challenge in Python, Triton, and CUDA.

- **Weekly Review:** At the end of every 2-day block (each group), spend 15 minutes reviewing challenging topics and refining your notes.

- **Flexibility:** Adjust the schedule if some topics or challenges require extra review or debugging time.

- **Documentation:** Keep a brief journal to record insights, optimization techniques, and any issues for future reference.
